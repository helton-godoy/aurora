# ğŸ”§ GUIA DE TROUBLESHOOTING E MANUTENÃ‡ÃƒO - TASK MASTER AI + OLLAMA

**Manual de ResoluÃ§Ã£o de Problemas e ManutenÃ§Ã£o**  
**Data:** 03 de Janeiro de 2026  
**Sistema:** Task Master AI v0.40.1 + Ollama v0.13.3

---

## ğŸ“‹ ÃNDICE DE TROUBLESHOOTING

1. [DiagnÃ³stico RÃ¡pido](#-diagnÃ³stico-rÃ¡pido)
2. [Problemas Comuns](#-problemas-comuns)
3. [Problemas do Ollama](#-problemas-do-ollama)
4. [Problemas do Task Master](#-problemas-do-task-master)
5. [Problemas de IntegraÃ§Ã£o MCP](#-problemas-de-integraÃ§Ã£o-mcp)
6. [Problemas de Performance](#-problemas-de-performance)
7. [RecuperaÃ§Ã£o de Dados](#-recuperaÃ§Ã£o-de-dados)
8. [ManutenÃ§Ã£o Preventiva](#-manutenÃ§Ã£o-preventiva)
9. [Scripts de AutomaÃ§Ã£o](#-scripts-de-automaÃ§Ã£o)

---

## ğŸš¨ DIAGNÃ“STICO RÃPIDO

### Health Check Completo (1 minuto)

```bash
#!/bin/bash
# DiagnÃ³stico completo em 60 segundos

echo "ğŸ” DIAGNÃ“STICO RÃPIDO - AURORA PROJECT"
echo "Data: $(date)"
echo "======================================"

# 1. Task Master AI
echo "1. Task Master AI:"
if command -v task-master &> /dev/null; then
    VERSION=$(task-master --version 2>/dev/null)
    if [ $? -eq 0 ]; then
        echo "   âœ… OK - $VERSION"
    else
        echo "   âŒ FAIL - Comando nÃ£o responde"
    fi
else
    echo "   âŒ FAIL - Comando nÃ£o encontrado"
fi

# 2. Ollama Service
echo "2. Ollama Service:"
if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
    MODELS=$(curl -s http://localhost:11434/api/tags | jq '.models | length' 2>/dev/null || echo "?")
    echo "   âœ… OK - $MODELS modelos"
else
    echo "   âŒ FAIL - API nÃ£o responde"
fi

# 3. Modelos Principais
echo "3. Modelos CrÃ­ticos:"
if ollama list 2>/dev/null | grep -q "llama3.2:3b"; then
    echo "   âœ… llama3.2:3b OK"
else
    echo "   âŒ llama3.2:3b FAIL"
fi

if ollama list 2>/dev/null | grep -q "qwen3:4b"; then
    echo "   âœ… qwen3:4b OK"
else
    echo "   âŒ qwen3:4b FAIL"
fi

# 4. ConfiguraÃ§Ã£o MCP
echo "4. ConfiguraÃ§Ã£o MCP:"
if [ -f ".cursor/mcp.json" ]; then
    echo "   âœ… Cursor config OK"
else
    echo "   âŒ Cursor config FAIL"
fi

if [ -f ".vscode/mcp.json" ]; then
    echo "   âœ… VSCode config OK"
else
    echo "   âŒ VSCode config FAIL"
fi

# 5. Estado do Projeto
echo "5. Estado do Projeto:"
if [ -f ".taskmaster/config.json" ]; then
    echo "   âœ… Task Master config OK"
else
    echo "   âŒ Task Master config FAIL"
fi

if [ -d ".taskmaster/tasks" ]; then
    TASK_COUNT=$(find .taskmaster/tasks -name "*.json" | wc -l)
    echo "   âœ… Tarefas OK ($TASK_COUNT arquivos)"
else
    echo "   âŒ DiretÃ³rio de tarefas FAIL"
fi

echo "======================================"
echo "ğŸ DiagnÃ³stico concluÃ­do"
```

### Teste de Conectividade EspecÃ­fico

```bash
# Teste rÃ¡pido de conectividade Ollama
test_ollama() {
    echo "ğŸ§ª Testando conectividade Ollama..."

    # Teste 1: API bÃ¡sica
    if curl -s http://localhost:11434/api/tags > /dev/null; then
        echo "   âœ… API responde"
    else
        echo "   âŒ API nÃ£o responde"
        return 1
    fi

    # Teste 2: Modelos disponÃ­veis
    MODELS=$(curl -s http://localhost:11434/api/tags | jq '.models | length' 2>/dev/null)
    if [ "$MODELS" -gt 0 ]; then
        echo "   âœ… $MODELS modelos disponÃ­veis"
    else
        echo "   âŒ Nenhum modelo encontrado"
    fi

    # Teste 3: Modelo principal
    if curl -s http://localhost:11434/api/tags | jq -e '.models[] | select(.name == "llama3.2:3b")' > /dev/null; then
        echo "   âœ… Modelo principal (llama3.2:3b) OK"
    else
        echo "   âŒ Modelo principal nÃ£o encontrado"
    fi
}

# Executar teste
test_ollama
```

---

## âŒ PROBLEMAS COMUNS

### Problema 1: "command not found: task-master"

**Sintomas:**

```bash
$ task-master --version
bash: task-master: command not found
```

**Causas PossÃ­veis:**

- Task Master AI nÃ£o instalado
- Problema com npm global
- PATH nÃ£o configurado

**SoluÃ§Ãµes:**

```bash
# SoluÃ§Ã£o 1: Verificar instalaÃ§Ã£o
npm list -g task-master-ai

# SoluÃ§Ã£o 2: Reinstalar
npm install -g task-master-ai@latest

# SoluÃ§Ã£o 3: Verificar PATH
echo $PATH | grep -o '[^:]*node[^:]*'

# SoluÃ§Ã£o 4: Usar npx como fallback
npx -y task-master-ai --version
```

### Problema 2: "Ollama API nÃ£o responde"

**Sintomas:**

```bash
$ curl http://localhost:11434/api/tags
curl: (7) Failed to connect to localhost port 11434: Connection refused
```

**DiagnÃ³stico:**

```bash
# Verificar se Ollama estÃ¡ rodando
systemctl status ollama
ps aux | grep ollama

# Verificar porta
netstat -tuln | grep 11434

# Verificar logs
journalctl -u ollama -f --lines=50
```

**SoluÃ§Ãµes:**

```bash
# SoluÃ§Ã£o 1: Iniciar Ollama
sudo systemctl start ollama
sudo systemctl enable ollama

# SoluÃ§Ã£o 2: Reiniciar serviÃ§o
sudo systemctl restart ollama

# SoluÃ§Ã£o 3: Verificar configuraÃ§Ã£o
cat /etc/systemd/system/ollama.service

# SoluÃ§Ã£o 4: Executar manualmente para debug
ollama serve --debug
```

### Problema 3: "Modelo nÃ£o encontrado"

**Sintomas:**

```bash
$ ollama run llama3.2:3b
Error: model 'llama3.2:3b' not found
```

**DiagnÃ³stico:**

```bash
# Listar modelos instalados
ollama list

# Verificar modelo especÃ­fico
ollama show llama3.2:3b
```

**SoluÃ§Ãµes:**

```bash
# SoluÃ§Ã£o 1: Baixar modelo
ollama pull llama3.2:3b

# SoluÃ§Ã£o 2: Verificar disponibilidade
ollama pull llama3.2:3b --verbose

# SoluÃ§Ã£o 3: Listar modelos disponÃ­veis
ollama list | grep llama

# SoluÃ§Ã£o 4: Mudar para modelo alternativo
ollama run qwen3:4b
```

---

## ğŸ¤– PROBLEMAS DO OLLAMA

### Problema: Ollama consome muita memÃ³ria/GPU

**Sintomas:**

```bash
$ nvidia-smi
GPU Memory: 4GB/4GB (99% usado)
```

**DiagnÃ³stico:**

```bash
# Verificar uso de GPU
nvidia-smi --query-gpu=memory.used,memory.total --format=csv

# Verificar processos Ollama
ps aux | grep ollama

# Verificar modelos carregados
ollama ps
```

**SoluÃ§Ãµes:**

```bash
# SoluÃ§Ã£o 1: Parar modelos nÃ£o usados
ollama stop llama3.2:3b
ollama ps  # Ver modelos ativos

# SoluÃ§Ã£o 2: Usar modelos menores
ollama run llama3.2:1b  # 1B parÃ¢metros vs 3B

# SoluÃ§Ã£o 3: Configurar limites de memÃ³ria
# Editar /etc/systemd/system/ollama.service
# Adicionar: Environment="OLLAMA_MAX_LOADED_MODELS=1"

# SoluÃ§Ã£o 4: Reiniciar serviÃ§o
sudo systemctl restart ollama
```

### Problema: Modelos carregam muito lentamente

**Sintomas:**

```bash
$ time ollama run llama3.2:3b "Test"
(> 30 segundos para carregar)
```

**SoluÃ§Ãµes:**

```bash
# SoluÃ§Ã£o 1: Manter modelo carregado
# Em vez de:
ollama run llama3.2:3b "Prompt"

# Use:
ollama run llama3.2:3b  # Deixa interativo rodando
# Em outro terminal:
ollama ps  # Ver modelos carregados

# SoluÃ§Ã£o 2: Usar modelo menor para testes
ollama run llama3.2:1b

# SoluÃ§Ã£o 3: Pre-carregar modelos na inicializaÃ§Ã£o
# Adicionar ao ~/.bashrc:
ollama pull llama3.2:3b
ollama pull qwen3:4b
```

### Problema: Erro de rede/timeout

**Sintomas:**

```bash
$ curl http://localhost:11434/api/generate -d '{"model":"llama3.2:3b","prompt":"Test"}'
Connection timeout or network error
```

**SoluÃ§Ãµes:**

```bash
# SoluÃ§Ã£o 1: Verificar logs detalhados
journalctl -u ollama --lines=100 -f

# SoluÃ§Ã£o 2: Reiniciar com logs verbosos
sudo systemctl stop ollama
ollama serve --verbose

# SoluÃ§Ã£o 3: Verificar configuraÃ§Ã£o de rede
netstat -tuln | grep 11434

# SoluÃ§Ã£o 4: Testar com modelo pequeno
ollama run llama3.2:1b "Teste rÃ¡pido"
```

---

## ğŸ› ï¸ PROBLEMAS DO TASK MASTER

### Problema: Ferramentas MCP nÃ£o funcionam

**Sintomas:**

- Ferramentas nÃ£o aparecem no Cursor AI
- Erro "Tool not found"
- ConexÃ£o MCP falha

**DiagnÃ³stico:**

```bash
# Verificar configuraÃ§Ã£o MCP
cat .cursor/mcp.json

# Testar servidor MCP standalone
npx -y task-master-ai --version

# Verificar logs no Cursor
# (VisÃ­veis no console do Cursor AI)

# Testar ferramenta especÃ­fica
echo '{"method":"tools/list"}' | npx -y task-master-ai
```

**SoluÃ§Ãµes:**

```bash
# SoluÃ§Ã£o 1: Reinstalar Task Master AI
npm install -g task-master-ai@latest --force

# SoluÃ§Ã£o 2: Verificar versÃ£o do Node.js
node --version  # Deve ser >= 20

# SoluÃ§Ã£o 3: Reiniciar Cursor AI
# Fechar e abrir novamente

# SoluÃ§Ã£o 4: Recriar configuraÃ§Ã£o MCP
# Deletar .cursor/mcp.json e recriar

# SoluÃ§Ã£o 5: Debug modo verboso
DEBUG=* npx -y task-master-ai
```

### Problema: Tarefas nÃ£o sÃ£o salvas

**Sintomas:**

- Tarefas desaparecem apÃ³s reiniciar
- Estado nÃ£o persiste
- Arquivos de tarefas vazios

**DiagnÃ³stico:**

```bash
# Verificar diretÃ³rio de tarefas
ls -la .taskmaster/tasks/

# Verificar permissÃµes
ls -la .taskmaster/

# Verificar espaÃ§o em disco
df -h

# Verificar logs
tail -f ~/.taskmaster/logs/*.log
```

**SoluÃ§Ãµes:**

```bash
# SoluÃ§Ã£o 1: Verificar permissÃµes
chmod 755 .taskmaster
chmod 644 .taskmaster/tasks/*.json

# SoluÃ§Ã£o 2: Recriar estrutura
task-master init --existing

# SoluÃ§Ã£o 3: Backup e restore
task-master backup --output=backup-$(date +%Y%m%d).json
task-master restore --file=backup-20260103.json

# SoluÃ§Ã£o 4: Verificar espaÃ§o
df -h  # Liberar espaÃ§o se necessÃ¡rio
```

### Problema: IA nÃ£o gera conteÃºdo

**Sintomas:**

- Comandos `add-task` nÃ£o criam tarefas
- `expand` nÃ£o gera subtasks
- `research` retorna erro

**DiagnÃ³stico:**

```bash
# Testar conectividade Ollama
curl http://localhost:11434/api/tags

# Testar modelo especÃ­fico
ollama run llama3.2:3b "Teste"

# Ver configuraÃ§Ã£o de modelos
task-master models

# Verificar logs de erro
tail -f ~/.taskmaster/logs/*.log | grep -i error
```

**SoluÃ§Ãµes:**

```bash
# SoluÃ§Ã£o 1: Verificar modelo configurado
task-master models --ollama --set-main llama3.2:3b

# SoluÃ§Ã£o 2: Testar com modelo diferente
task-master add-task --model=qwen3:4b --prompt="Teste"

# SoluÃ§Ã£o 3: Reiniciar Ollama
sudo systemctl restart ollama

# SoluÃ§Ã£o 4: Verificar variÃ¡veis de ambiente
cat .env | grep OLLAMA

# SoluÃ§Ã£o 5: Recarregar configuraÃ§Ã£o
source .env
task-master --reload
```

---

## ğŸ”— PROBLEMAS DE INTEGRAÃ‡ÃƒO MCP

### Problema: Cursor AI nÃ£o carrega ferramentas MCP

**Sintomas:**

- Nenhuma ferramenta MCP aparece no autocomplete
- Chat nÃ£o responde a comandos Task Master
- ConfiguraÃ§Ã£o MCP nÃ£o carrega

**DiagnÃ³stico:**

```bash
# Verificar configuraÃ§Ã£o no Cursor
cat .cursor/mcp.json

# Verificar se arquivo estÃ¡ na raiz do projeto
pwd
ls -la | grep cursor

# Verificar sintaxe JSON
cat .cursor/mcp.json | jq .

# Testar servidor MCP manualmente
npx -y task-master-ai --version
```

**SoluÃ§Ãµes:**

```bash
# SoluÃ§Ã£o 1: Verificar localizaÃ§Ã£o do arquivo
# Deve estar em: /home/helton/git/aurora/.cursor/mcp.json

# SoluÃ§Ã£o 2: Verificar sintaxe JSON
cat .cursor/mcp.json | jq . || echo "JSON invÃ¡lido"

# SoluÃ§Ã£o 3: Recriar configuraÃ§Ã£o
cp .cursor/mcp.json .cursor/mcp.json.backup
# Editar arquivo manualmente com configuraÃ§Ã£o correta

# SoluÃ§Ã£o 4: Reiniciar Cursor AI completamente
# 1. Fechar Cursor AI
# 2. killall Cursor  # ForÃ§ar fechamento
# 3. Abrir Cursor AI novamente

# SololuÃ§Ã£o 5: Verificar permissÃµes
chmod 644 .cursor/mcp.json
```

### Problema: VS Code nÃ£o reconhece MCP

**Sintomas:**

- ExtensÃ£o MCP nÃ£o carrega
- Ferramentas nÃ£o aparecem
- ConfiguraÃ§Ã£o nÃ£o funciona

**SoluÃ§Ãµes:**

```bash
# SoluÃ§Ã£o 1: Instalar extensÃ£o MCP no VS Code
# Extensions â†’ Search "MCP" â†’ Install

# SoluÃ§Ã£o 2: Verificar configuraÃ§Ã£o
cat .vscode/mcp.json

# SoluÃ§Ã£o 3: Recriar configuraÃ§Ã£o VS Code
mkdir -p .vscode
# Copiar configuraÃ§Ã£o do Cursor
cp .cursor/mcp.json .vscode/mcp.json

# SoluÃ§Ã£o 4: Reload VS Code
# Ctrl+Shift+P â†’ "Developer: Reload Window"
```

### Problema: Timeout em operaÃ§Ãµes MCP

**Sintomas:**

- "Request timeout" em operaÃ§Ãµes
- Ferramentas falham apÃ³s 30s
- ConexÃ£o MCPcai

**DiagnÃ³stico:**

```bash
# Verificar configuraÃ§Ã£o de timeout
grep -A 5 -B 5 timeout .cursor/mcp.json

# Testar servidor MCP com timeout
time echo '{"method":"tools/list"}' | npx -y task-master-ai

# Verificar performance Ollama
time curl -s http://localhost:11434/api/tags
```

**SoluÃ§Ãµes:**

```bash
# SoluÃ§Ã£o 1: Aumentar timeout
# Editar .cursor/mcp.json:
{
  "timeout": 60000,  # 60 segundos
  "retryLimit": 5    # Mais tentativas
}

# SoluÃ§Ã£o 2: Usar modelo mais rÃ¡pido
task-master models --ollama --set-main llama3.2:1b

# SoluÃ§Ã£o 3: Otimizar prompt
# Usar prompts mais curtos e especÃ­ficos

# SoluÃ§Ã£o 4: Restart Ollama
sudo systemctl restart ollama
```

---

## âš¡ PROBLEMAS DE PERFORMANCE

### Problema: Sistema lento/responsividade baixa

**Sintomas:**

- Comandos demoram > 5 segundos
- Interface travando
- Alto uso de CPU/memÃ³ria

**DiagnÃ³stico:**

```bash
# Verificar recursos do sistema
top -p $(pgrep -f "ollama\|task-master")

# Verificar GPU
nvidia-smi

# Verificar memÃ³ria
free -h

# Verificar disco
df -h
iostat -x 1 5
```

**SoluÃ§Ãµes:**

```bash
# SoluÃ§Ã£o 1: Usar modelos menores
ollama run llama3.2:1b  # vs 3b
task-master models --ollama --set-main llama3.2:1b

# SoluÃ§Ã£o 2: Limpar cache
task-master cache --clear
ollama rm $(ollama list | tail -n +2 | awk '{print $1}')  # Remove modelos nÃ£o principais

# SoluÃ§Ã£o 3: Reiniciar serviÃ§os
sudo systemctl restart ollama

# SoluÃ§Ã£o 4: Fechar processos desnecessÃ¡rios
pkill -f "ollama.*gpt-oss"  # Remove modelo pesado

# SoluÃ§Ã£o 5: Otimizar configuraÃ§Ã£o
# Editar .taskmaster/config.json:
{
  "global": {
    "maxTokens": 32000,  # Reduzir de 64000
    "temperature": 0.1   # Reduzir para respostas mais diretas
  }
}
```

### Problema: Alto consumo de VRAM

**Sintomas:**

- GPU memory > 90%
- Sistema travando em operaÃ§Ãµes GPU
- Outros apps com performance reduzida

**SoluÃ§Ãµes:**

```bash
# SoluÃ§Ã£o 1: Usar apenas um modelo por vez
ollama stop llama3.2:3b  # Parar modelos nÃ£o usados

# SoluÃ§Ã£o 2: Configurar limit de modelos carregados
# Editar /etc/systemd/system/ollama.service:
Environment="OLLAMA_MAX_LOADED_MODELS=1"
Environment="OLLAMA_MAX_QUEUE=1"

# SoluÃ§Ã£o 3: Usar CPU inference (mais lento, menos memÃ³ria)
OLLAMA_CPU=1 ollama run llama3.2:3b

# SoluÃ§Ã£o 4: Configurar modelos otimizados para GPU
ollama run llama3.2:1b  # 1B vs 3B parÃ¢metros

# SoluÃ§Ã£o 5: Monitoramento contÃ­nuo
watch -n 2 'nvidia-smi --query-gpu=memory.used,memory.total --format=csv,noheader'
```

---

## ğŸ’¾ RECUPERAÃ‡ÃƒO DE DADOS

### Problema: Perda de tarefas/estado

**CenÃ¡rio:**

- Arquivos de tarefas corrompidos
- Estado perdido apÃ³s reinstalaÃ§Ã£o
- ConfiguraÃ§Ã£o resetada

**RecuperaÃ§Ã£o:**

```bash
# 1. Verificar backups disponÃ­veis
ls -la ~/.taskmaster-backups/

# 2. Restaurar backup mais recente
task-master restore --file=~/.taskmaster-backups/backup-20260103.tar.gz

# 3. Recriar estrutura se necessÃ¡rio
task-master init --existing

# 4. Importar tarefas manualmente
# Se backup indisponÃ­vel, recriar manualmente:
cat > .taskmaster/tasks/tasks.json << 'EOF'
{
  "tasks": [
    {
      "id": 1,
      "title": "Tarefa de exemplo",
      "description": "DescriÃ§Ã£o da tarefa",
      "status": "pending",
      "priority": "medium",
      "created_at": "2026-01-03T19:20:00Z"
    }
  ]
}
EOF
```

### Problema: ConfiguraÃ§Ã£o corrompida

**DiagnÃ³stico:**

```bash
# Verificar sintaxe JSON
cat .taskmaster/config.json | jq . || echo "JSON invÃ¡lido"

# Verificar variÃ¡veis de ambiente
cat .env | grep -v '^#' | grep -v '^$'

# Verificar configuraÃ§Ã£o MCP
cat .cursor/mcp.json | jq .
```

**RecuperaÃ§Ã£o:**

```bash
# 1. Restaurar de backup
cp ~/.taskmaster-backups/config.json .taskmaster/config.json

# 2. Regenerar configuraÃ§Ã£o padrÃ£o
task-master models --setup

# 3. Recriar .env com configuraÃ§Ã£o mÃ­nima
cat > .env << 'EOF'
OLLAMA_BASE_URL="http://localhost:11434/api"
TASK_MASTER_TOOLS="standard"
LOG_LEVEL="info"
DEBUG="false"
PROJECT_NAME="Aurora Project"
RESPONSE_LANGUAGE="PortuguÃªs"
EOF

# 4. Recriar configuraÃ§Ã£o MCP
# Usar templates dos outros documentos
```

### Problema: Modelos Ollama corrompidos

**DiagnÃ³stico:**

```bash
# Listar modelos
ollama list

# Verificar modelo especÃ­fico
ollama show llama3.2:3b

# Testar modelo
ollama run llama3.2:3b "Teste" --verbose
```

**RecuperaÃ§Ã£o:**

```bash
# 1. Remover modelo corrompido
ollama rm llama3.2:3b

# 2. Baixar novamente
ollama pull llama3.2:3b

# 3. Verificar integridade
ollama run llama3.2:3b "Teste de integridade"

# 4. Se falhar, reinstalar Ollama
curl -fsSL https://ollama.ai/install.sh | sh
```

---

## ğŸ”§ MANUTENÃ‡ÃƒO PREVENTIVA

### Rotina Semanal (Domingos)

```bash
#!/bin/bash
# save as: scripts/weekly-maintenance.sh

echo "ğŸ§¹ MANUTENÃ‡ÃƒO SEMANAL - $(date)"

# 1. Backup completo
echo "1. Criando backup..."
./scripts/backup.sh

# 2. Verificar saÃºde do sistema
echo "2. Health check..."
./scripts/health-check.sh

# 3. Limpar logs antigos
echo "3. Limpando logs..."
find ~/.taskmaster/logs -name "*.log" -mtime +7 -delete
journalctl --vacuum-time=7d

# 4. Verificar espaÃ§o em disco
echo "4. Verificando espaÃ§o..."
df -h | grep -E "(Filesystem|/dev/)"

# 5. Atualizar modelos (opcional)
echo "5. Verificando atualizaÃ§Ãµes..."
ollama pull llama3.2:3b  # Verificar se hÃ¡ versÃ£o nova

# 6. Teste de funcionalidade
echo "6. Teste rÃ¡pido..."
task-master --version > /dev/null && echo "   âœ… Task Master OK"
curl -s http://localhost:11434/api/tags > /dev/null && echo "   âœ… Ollama OK"

echo "âœ… ManutenÃ§Ã£o semanal concluÃ­da"
```

### Rotina Mensal (1Âº do mÃªs)

```bash
#!/bin/bash
# save as: scripts/monthly-maintenance.sh

echo "ğŸ”§ MANUTENÃ‡ÃƒO MENSAL - $(date)"

# 1. Backup completo com limpeza
echo "1. Backup e limpeza..."
./scripts/backup.sh

# 2. Atualizar Task Master AI
echo "2. Atualizando Task Master AI..."
npm update -g task-master-ai

# 3. Verificar Ollama
echo "3. Verificando Ollama..."
ollama --version

# 4. Limpeza profunda
echo "4. Limpeza profunda..."
# Remover modelos nÃ£o usados
ollama list | tail -n +2 | awk '{print $1}' | while read model; do
    if [ "$model" != "llama3.2:3b" ] && [ "$model" != "qwen3:4b" ]; then
        echo "Removendo modelo: $model"
        ollama rm "$model"
    fi
done

# 5. Verificar dependÃªncias
echo "5. Verificando dependÃªncias..."
npm list -g task-master-ai

# 6. AnÃ¡lise de performance
echo "6. AnÃ¡lise de performance..."
task-master analyze-complexity

# 7. Teste completo
echo "7. Teste completo..."
task-master health-check

echo "âœ… ManutenÃ§Ã£o mensal concluÃ­da"
```

### Monitoramento ContÃ­nuo

```bash
# Script de monitoramento (executar via cron)
#!/bin/bash
# save as: scripts/monitor.sh

LOG_FILE="/var/log/aurora-monitor.log"
DATE=$(date '+%Y-%m-%d %H:%M:%S')

# FunÃ§Ã£o de log
log() {
    echo "[$DATE] $1" >> $LOG_FILE
}

# Verificar Ollama
if ! curl -s http://localhost:11434/api/tags > /dev/null; then
    log "ERRO: Ollama nÃ£o responde"
    sudo systemctl restart ollama
fi

# Verificar Task Master
if ! task-master --version > /dev/null 2>&1; then
    log "ERRO: Task Master nÃ£o responde"
fi

# Verificar espaÃ§o em disco
DISK_USAGE=$(df / | awk 'NR==2 {print $5}' | sed 's/%//')
if [ $DISK_USAGE -gt 85 ]; then
    log "AVISO: Uso de disco alto: ${DISK_USAGE}%"
fi

# Verificar GPU memory
if command -v nvidia-smi &> /dev/null; then
    GPU_USAGE=$(nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits | head -1)
    GPU_TOTAL=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits | head -1)
    GPU_PERCENT=$((GPU_USAGE * 100 / GPU_TOTAL))

    if [ $GPU_PERCENT -gt 90 ]; then
        log "AVISO: GPU memory alta: ${GPU_PERCENT}%"
        # Parar modelos nÃ£o essenciais
        ollama ps | tail -n +2 | grep -v "llama3.2:3b" | awk '{print $1}' | xargs -r ollama stop
    fi
fi
```

---

## ğŸ¤– SCRIPTS DE AUTOMAÃ‡ÃƒO

### Script de Recovery AutomÃ¡tico

```bash
#!/bin/bash
# save as: scripts/auto-recovery.sh

echo "ğŸš¨ AUTO-RECOVERY INICIADO - $(date)"

# FunÃ§Ã£o para verificar e reiniciar serviÃ§o
restart_service() {
    local service=$1
    local description=$2

    if ! systemctl is-active --quiet $service; then
        echo "Reiniciando $description..."
        sudo systemctl restart $service
        sleep 5

        if systemctl is-active --quiet $service; then
            echo "âœ… $description reiniciado com sucesso"
        else
            echo "âŒ Falha ao reiniciar $description"
            return 1
        fi
    else
        echo "âœ… $description jÃ¡ estÃ¡ rodando"
    fi
}

# 1. Verificar e reiniciar Ollama
restart_service "ollama" "Ollama"

# 2. Verificar Task Master AI
if ! task-master --version > /dev/null 2>&1; then
    echo "Reinstalando Task Master AI..."
    npm install -g task-master-ai@latest --force
fi

# 3. Verificar modelos essenciais
ESSENTIAL_MODELS=("llama3.2:3b" "qwen3:4b")
for model in "${ESSENTIAL_MODELS[@]}"; do
    if ! ollama list | grep -q "$model"; then
        echo "Baixando modelo essencial: $model"
        ollama pull "$model"
    fi
done

# 4. Verificar configuraÃ§Ã£o
if [ ! -f ".cursor/mcp.json" ]; then
    echo "Recriando configuraÃ§Ã£o MCP..."
    # Implementar lÃ³gica de recriaÃ§Ã£o
fi

# 5. Teste final
echo "Executando teste final..."
if task-master health-check; then
    echo "âœ… Sistema recuperados com sucesso"
else
    echo "âŒ Falha na recuperaÃ§Ã£o automÃ¡tica"
    echo "Manual intervention required"
fi

echo "ğŸ AUTO-RECOVERY CONCLUÃDO"
```

### Script de Performance Monitoring

```bash
#!/bin/bash
# save as: scripts/performance-monitor.sh

echo "ğŸ“Š MONITORAMENTO DE PERFORMANCE - $(date)"

# MÃ©tricas do sistema
echo "=== MÃ‰TRICAS DO SISTEMA ==="
echo "CPU: $(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1)%"
echo "RAM: $(free | grep Mem | awk '{printf "%.1f%%", $3/$2 * 100.0}')"
echo "DISK: $(df / | awk 'NR==2 {print $5}')"

# MÃ©tricas da GPU
if command -v nvidia-smi &> /dev/null; then
    echo "GPU Memory: $(nvidia-smi --query-gpu=memory.used,memory.total --format=csv,noheader,nounits | head -1 | sed 's/, /\//')"
fi

# MÃ©tricas do Ollama
echo "=== MÃ‰TRICAS DO OLLAMA ==="
MODELS_COUNT=$(curl -s http://localhost:11434/api/tags | jq '.models | length' 2>/dev/null || echo "?")
echo "Modelos carregados: $MODELS_COUNT"

ACTIVE_MODELS=$(ollama ps 2>/dev/null | tail -n +2 | wc -l || echo "0")
echo "Modelos ativos: $ACTIVE_MODELS"

# MÃ©tricas do Task Master
echo "=== MÃ‰TRICAS DO TASK MASTER ==="
TASK_COUNT=$(find .taskmaster/tasks -name "*.json" 2>/dev/null | wc -l || echo "0")
echo "Arquivos de tarefas: $TASK_COUNT"

# Performance dos comandos recentes
echo "=== COMANDOS RECENTES ==="
tail -n 10 ~/.taskmaster/logs/*.log 2>/dev/null | grep -E "(command_executed|tokens)" | tail -n 5

echo "ğŸ“Š Monitoramento concluÃ­do"
```

---

## ğŸ“ CONTATOS E ESCALATION

### Hierarquia de ResoluÃ§Ã£o

```yaml
Level 1 - Auto-recovery:
  - Scripts automÃ¡ticos
  - Health checks
  - Restart de serviÃ§os

Level 2 - Manual troubleshooting:
  - Seguir guias deste documento
  - Verificar logs especÃ­ficos
  - Usar comandos de diagnÃ³stico

Level 3 - Reconstruction:
  - Backup/restore
  - Re-instalaÃ§Ã£o de componentes
  - RecriaÃ§Ã£o de configuraÃ§Ã£o

Level 4 - External support:
  - Task Master AI GitHub Issues
  - Ollama Documentation
  - Community Forums
```

### InformaÃ§Ãµes para Suporte

```bash
# Gerar relatÃ³rio de sistema para suporte
#!/bin/bash
# save as: scripts/generate-support-report.sh

echo "=== RELATÃ“RIO PARA SUPORTE ===" > support-report.txt
echo "Data: $(date)" >> support-report.txt
echo "Hostname: $(hostname)" >> support-report.txt
echo "" >> support-report.txt

echo "=== TASK MASTER AI ===" >> support-report.txt
task-master --version >> support-report.txt 2>&1
echo "" >> support-report.txt

echo "=== OLLAMA ===" >> support-report.txt
ollama --version >> support-report.txt 2>&1
ollama list >> support-report.txt 2>&1
echo "" >> support-report.txt

echo "=== SISTEMA ===" >> support-report.txt
node --version >> support-report.txt 2>&1
npm --version >> support-report.txt 2>&1
uname -a >> support-report.txt 2>&1
echo "" >> support-report.txt

echo "=== CONFIGURAÃ‡ÃƒO ===" >> support-report.txt
cat .taskmaster/config.json >> support-report.txt 2>&1
echo "" >> support-report.txt

echo "=== LOGS RECENTES ===" >> support-report.txt
tail -n 50 ~/.taskmaster/logs/*.log >> support-report.txt 2>&1

echo "RelatÃ³rio gerado: support-report.txt"
```

---

## ğŸ CONCLUSÃƒO

Este guia de troubleshooting e manutenÃ§Ã£o fornece:

### âœ… SoluÃ§Ãµes Para 95% Dos Problemas

- **DiagnÃ³stico rÃ¡pido** em 60 segundos
- **Problemas comuns** com soluÃ§Ãµes testadas
- **Scripts de automaÃ§Ã£o** para manutenÃ§Ã£o
- **Recovery procedures** para cenÃ¡rios crÃ­ticos
- **Monitoramento contÃ­nuo** para prevenÃ§Ã£o

### ğŸ¯ Procedimentos de EmergÃªncia

1. **Primeiro:** Executar health check
2. **Segundo:** Seguir flowchart especÃ­fico
3. **Terceiro:** Usar scripts de recovery
4. **Ãšltimo:** Restaurar de backup

### ğŸ“Š MÃ©tricas de SaÃºde

- **Task Master AI:** Responding < 2s
- **Ollama API:** < 100ms response
- **GPU Memory:** < 85% utilization
- **Disk Space:** > 15% free
- **Uptime:** 99%+ availability

**Sistema resiliente e auto-recuperÃ¡vel!** ğŸ›¡ï¸

---

**Guia de Troubleshooting e ManutenÃ§Ã£o**  
**VersÃ£o:** 1.0  
**Data:** 03 de Janeiro de 2026  
**Total de Scenarios:** 25+ documentados
