# üìã REFER√äNCIA COMPLETA DE CONFIGURA√á√ïES - TASK MASTER AI + OLLAMA

**Manual de Refer√™ncia de Configura√ß√µes**  
**Data:** 03 de Janeiro de 2026  
**Sistema:** Task Master AI v0.40.1 + Ollama v0.13.3

---

## üìã √çNDICE DE CONFIGURA√á√ïES

1. [Estrutura de Arquivos](#-estrutura-de-arquivos)
2. [Vari√°veis de Ambiente (.env)](#-vari√°veis-de-ambiente-env)
3. [Configura√ß√£o MCP Cursor (.cursor/mcp.json)](#-configura√ß√£o-mcp-cursor-cursormcpjson)
4. [Configura√ß√£o MCP VS Code (.vscode/mcp.json)](#-configura√ß√£o-mcp-vs-code-vscodemcpjson)
5. [Configura√ß√£o Task Master (.taskmaster/config.json)](#-configura√ß√£o-task-master-taskmasterconfigjson)
6. [Configura√ß√£o de Modelos](#-configura√ß√£o-de-modelos)
7. [Configura√ß√µes do Sistema](#-configura√ß√µes-do-sistema)
8. [Templates de Configura√ß√£o](#-templates-de-configura√ß√£o)
9. [Valida√ß√£o de Configura√ß√µes](#-valida√ß√£o-de-configura√ß√µes)
10. [Migra√ß√£o e Backup](#-migra√ß√£o-e-backup)

---

## üìÅ ESTRUTURA DE ARQUIVOS

### Hierarquia Completa

```
/home/helton/git/aurora/
‚îú‚îÄ‚îÄ .env                                    # Vari√°veis de ambiente globais
‚îú‚îÄ‚îÄ .taskmaster/                            # Configura√ß√£o principal Task Master
‚îÇ   ‚îú‚îÄ‚îÄ config.json                         # Configura√ß√£o de modelos e global
‚îÇ   ‚îú‚îÄ‚îÄ state.json                          # Estado atual do projeto
‚îÇ   ‚îú‚îÄ‚îÄ tasks/                              # Gerenciamento de tarefas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tasks.json                      # Tarefas em formato JSON
‚îÇ   ‚îú‚îÄ‚îÄ docs/                               # Documenta√ß√£o do projeto
‚îÇ   ‚îú‚îÄ‚îÄ reports/                            # Relat√≥rios gerados
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ task-complexity-report.json     # Relat√≥rio de complexidade
‚îÇ   ‚îî‚îÄ‚îÄ templates/                          # Templates de documentos
‚îú‚îÄ‚îÄ .cursor/                                # Configura√ß√£o espec√≠fica Cursor AI
‚îÇ   ‚îú‚îÄ‚îÄ mcp.json                            # Configura√ß√£o MCP principal
‚îÇ   ‚îú‚îÄ‚îÄ commands/                           # Comandos personalizados (20+)
‚îÇ   ‚îî‚îÄ‚îÄ rules/                              # Regras de comportamento
‚îú‚îÄ‚îÄ .vscode/                                # Configura√ß√£o para VS Code
‚îÇ   ‚îî‚îÄ‚îÄ mcp.json                            # Configura√ß√£o MCP espelhada
‚îú‚îÄ‚îÄ scripts/                                # Scripts de automa√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ health-check.sh                     # Health check automatizado
‚îÇ   ‚îú‚îÄ‚îÄ backup.sh                           # Backup automatizado
‚îÇ   ‚îú‚îÄ‚îÄ update.sh                           # Script de atualiza√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ auto-recovery.sh                    # Recovery autom√°tico
‚îÇ   ‚îú‚îÄ‚îÄ performance-monitor.sh              # Monitor de performance
‚îÇ   ‚îî‚îÄ‚îÄ generate-support-report.sh          # Relat√≥rio para suporte
‚îî‚îÄ‚îÄ tools/                                  # Ferramentas auxiliares
    ‚îî‚îÄ‚îÄ git-commit-classify.sh              # Classificador de commits Git
```

### Prop√≥sitos dos Arquivos

| Arquivo/Diret√≥rio              | Prop√≥sito               | Frequ√™ncia de Edi√ß√£o |
| ------------------------------ | ----------------------- | -------------------- |
| `.env`                         | Vari√°veis de ambiente   | Rara                 |
| `.taskmaster/config.json`      | Configura√ß√£o de modelos | Ocasional            |
| `.cursor/mcp.json`             | Integra√ß√£o Cursor AI    | Rara                 |
| `.vscode/mcp.json`             | Integra√ß√£o VS Code      | Rara                 |
| `.taskmaster/tasks/tasks.json` | Dados das tarefas       | Frequente            |
| `scripts/`                     | Automa√ß√£o               | Ocasional            |

---

## üîß VARI√ÅVEIS DE AMBIENTE (.env)

### Arquivo Completo

```bash
# =====================================================
# CONFIGURA√á√ÉO COMPLETA DE VARI√ÅVEIS DE AMBIENTE
# TASK MASTER AI + OLLAMA LOCAL
# =====================================================

# ====================
# OLLAMA CONFIGURATION
# ====================
OLLAMA_API_KEY=""
OLLAMA_BASE_URL="http://localhost:11434/api"

# ====================
# TASK MASTER TOOLS
# ====================
TASK_MASTER_TOOLS="standard"

# ====================
# AI PROVIDERS API KEYS
# ====================
ANTHROPIC_API_KEY=""
PERPLEXITY_API_KEY=""
OPENAI_API_KEY=""
GOOGLE_API_KEY=""
MISTRAL_API_KEY=""
XAI_API_KEY=""
GROQ_API_KEY=""
OPENROUTER_API_KEY=""
AZURE_OPENAI_API_KEY=""
GITHUB_API_KEY=""

# ====================
# DEBUGGING & LOGGING
# ====================
DEBUG="false"
LOG_LEVEL="info"
ANONYMOUS_TELEMETRY="true"

# ====================
# TASK MASTER SETTINGS
# ====================
PROJECT_NAME="Aurora Project"
RESPONSE_LANGUAGE="Portugu√™s"
ENABLE_CODEBASE_ANALYSIS="true"
ENABLE_PROXY="false"
DEFAULT_NUM_TASKS="10"
DEFAULT_SUBTASKS="5"
DEFAULT_PRIORITY="medium"
```

### Descri√ß√£o Detalhada das Vari√°veis

#### Configura√ß√£o Ollama

```bash
# URL base da API Ollama
OLLAMA_BASE_URL="http://localhost:11434/api"

# Chave de API (vazia para uso local)
OLLAMA_API_KEY=""
```

**Configura√ß√µes Alternativas:**

```bash
# Para Ollama remoto
OLLAMA_BASE_URL="https://ollama.exemplo.com/api"

# Para Ollama com autentica√ß√£o
OLLAMA_BASE_URL="http://localhost:11434/api"
OLLAMA_API_KEY="sua_chave_api_aqui"
```

#### Configura√ß√£o de Ferramentas

```bash
# Modo de ferramentas Task Master
TASK_MASTER_TOOLS="standard"  # ou "advanced" ou "minimal"
```

**Op√ß√µes Dispon√≠veis:**

- `standard`: 14 ferramentas (padr√£o)
- `advanced`: Todas as ferramentas + experimentais
- `minimal`: Apenas ferramentas essenciais

#### APIs de Provedores de IA

```bash
# Anthropic (Claude)
ANTHROPIC_API_KEY=""

# Perplexity (Pesquisa)
PERPLEXITY_API_KEY=""

# OpenAI (GPT-4, etc.)
OPENAI_API_KEY=""

# Google (Gemini)
GOOGLE_API_KEY=""

# Outros provedores
MISTRAL_API_KEY=""
XAI_API_KEY=""
GROQ_API_KEY=""
OPENROUTER_API_KEY=""
AZURE_OPENAI_API_KEY=""
```

**Configura√ß√£o para Produ√ß√£o:**

```bash
# Adicionar chaves reais (NUNCA no Git!)
ANTHROPIC_API_KEY="sk-ant-..."
PERPLEXITY_API_KEY="pplx-..."
OPENAI_API_KEY="sk-..."
```

#### Configura√ß√µes de Debug

```bash
# Modo debug (produ√ß√£o: false)
DEBUG="false"

# N√≠vel de log (error, warn, info, debug)
LOG_LEVEL="info"

# Telemetria an√¥nima
ANONYMOUS_TELEMETRY="true"
```

**Configura√ß√µes para Desenvolvimento:**

```bash
DEBUG="true"
LOG_LEVEL="debug"
ANONYMOUS_TELEMETRY="false"
```

#### Configura√ß√µes do Projeto

```bash
# Nome do projeto
PROJECT_NAME="Aurora Project"

# Idioma de resposta
RESPONSE_LANGUAGE="Portugu√™s"  # ou "English", "Espa√±ol", etc.

# An√°lise de codebase
ENABLE_CODEBASE_ANALYSIS="true"

# Proxy (se necess√°rio)
ENABLE_PROXY="false"

# Padr√µes para cria√ß√£o de tarefas
DEFAULT_NUM_TASKS="10"
DEFAULT_SUBTASKS="5"
DEFAULT_PRIORITY="medium"  # low, medium, high, critical
```

---

## üîó CONFIGURA√á√ÉO MCP CURSOR (.cursor/mcp.json)

### Configura√ß√£o Completa

```json
{
  "mcpServers": {
    "task-master-ai": {
      "command": "npx",
      "args": ["-y", "task-master-ai"],
      "env": {
        "TASK_MASTER_TOOLS": "standard",
        "OLLAMA_BASE_URL": "http://localhost:11434/api",
        "OLLAMA_API_KEY": "",
        "ANTHROPIC_API_KEY": "",
        "PERPLEXITY_API_KEY": "",
        "OPENAI_API_KEY": "",
        "GOOGLE_API_KEY": "",
        "XAI_API_KEY": "",
        "OPENROUTER_API_KEY": "",
        "MISTRAL_API_KEY": "",
        "AZURE_OPENAI_API_KEY": "",
        "GROQ_API_KEY": "",
        "GITHUB_API_KEY": "",
        "LOG_LEVEL": "info",
        "DEBUG": "false"
      },
      "disabled": false,
      "timeout": 30000,
      "retryLimit": 3
    }
  },
  "global": {
    "enableAnalytics": true,
    "enableErrorReporting": false,
    "logLevel": "info"
  }
}
```

### Par√¢metros Detalhados

#### Configura√ß√£o do Servidor

```json
{
  "command": "npx",
  "args": ["-y", "task-master-ai"],
  "env": { ... },
  "disabled": false,
  "timeout": 30000,
  "retryLimit": 3
}
```

**Par√¢metros Explicados:**

- `command`: Comando para executar o servidor
- `args`: Argumentos passados para o comando
- `env`: Vari√°veis de ambiente espec√≠ficas para MCP
- `disabled`: Se o servidor est√° desabilitado
- `timeout`: Timeout em millisegundos (30s = 30000ms)
- `retryLimit`: N√∫mero de tentativas em caso de falha

#### Configura√ß√µes Alternativas

**Para Debug:**

```json
{
  "timeout": 60000,
  "retryLimit": 5,
  "env": {
    "DEBUG": "true",
    "LOG_LEVEL": "debug"
  }
}
```

**Para Produ√ß√£o:**

```json
{
  "timeout": 15000,
  "retryLimit": 2,
  "env": {
    "DEBUG": "false",
    "LOG_LEVEL": "warn"
  }
}
```

**Para M√∫ltiplos Servidores:**

```json
{
  "mcpServers": {
    "task-master-ai": {
      "command": "npx",
      "args": ["-y", "task-master-ai"],
      "env": { ... }
    },
    "outro-servidor": {
      "command": "outro-comando",
      "args": ["--param"],
      "env": { ... }
    }
  }
}
```

---

## üíª CONFIGURA√á√ÉO MCP VS CODE (.vscode/mcp.json)

### Configura√ß√£o Completa

```json
{
  "mcpServers": {
    "task-master-ai": {
      "command": "npx",
      "args": ["-y", "task-master-ai"],
      "env": {
        "TASK_MASTER_TOOLS": "standard",
        "OLLAMA_BASE_URL": "http://localhost:11434/api",
        "OLLAMA_API_KEY": "",
        "ANTHROPIC_API_KEY": "",
        "PERPLEXITY_API_KEY": "",
        "OPENAI_API_KEY": "",
        "GOOGLE_API_KEY": "",
        "XAI_API_KEY": "",
        "OPENROUTER_API_KEY": "",
        "MISTRAL_API_KEY": "",
        "AZURE_OPENAI_API_KEY": "",
        "GROQ_API_KEY": "",
        "GITHUB_API_KEY": "",
        "LOG_LEVEL": "info",
        "DEBUG": "false"
      },
      "disabled": false,
      "timeout": 30000,
      "retryLimit": 3
    }
  }
}
```

### Diferen√ßas do Cursor AI

```json
{
  "global": {
    // VS Code n√£o usa global na configura√ß√£o MCP
  }
}
```

**Nota:** A configura√ß√£o do VS Code √© essentially id√™ntica ao Cursor, exceto pela se√ß√£o `global` que n√£o √© suportada.

---

## üõ†Ô∏è CONFIGURA√á√ÉO TASK MASTER (.taskmaster/config.json)

### Configura√ß√£o Completa

```json
{
  "models": {
    "main": {
      "provider": "ollama",
      "modelId": "llama3.2:3b",
      "maxTokens": 64000,
      "temperature": 0.2,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "baseURL": "http://localhost:11434/api"
    },
    "code": {
      "provider": "ollama",
      "modelId": "qwen3:4b",
      "maxTokens": 32000,
      "temperature": 0.1,
      "top_p": 0.8,
      "repeat_penalty": 1.05,
      "baseURL": "http://localhost:11434/api"
    },
    "research": {
      "provider": "perplexity",
      "modelId": "sonar",
      "maxTokens": 8700,
      "temperature": 0.1,
      "top_p": 0.9
    },
    "fallback": {
      "provider": "anthropic",
      "modelId": "claude-3-7-sonnet-20250219",
      "maxTokens": 120000,
      "temperature": 0.2,
      "top_p": 0.9
    }
  },
  "global": {
    "logLevel": "info",
    "debug": false,
    "defaultNumTasks": 10,
    "defaultSubtasks": 5,
    "defaultPriority": "medium",
    "projectName": "Aurora Project",
    "ollamaBaseURL": "http://localhost:11434/api",
    "responseLanguage": "Portugu√™s",
    "enableCodebaseAnalysis": true,
    "enableProxy": false,
    "anonymousTelemetry": true,
    "mcpIntegration": true,
    "cursorIntegration": true,
    "vscodeIntegration": true,
    "maxConcurrentRequests": 3,
    "enableCache": true,
    "cacheTimeout": 3600
  },
  "mcp": {
    "enabled": true,
    "serverName": "task-master-ai",
    "toolsMode": "standard",
    "timeout": 30000,
    "retryLimit": 3,
    "healthCheckInterval": 300,
    "enableMetrics": true
  },
  "advanced": {
    "customTemplates": {
      "task": "templates/custom-task.md",
      "report": "templates/custom-report.md"
    },
    "integrations": {
      "github": {
        "enabled": false,
        "token": "",
        "owner": "",
        "repo": ""
      },
      "jira": {
        "enabled": false,
        "url": "",
        "username": "",
        "token": ""
      }
    },
    "customCommands": {
      "enabled": true,
      "path": ".cursor/commands"
    }
  }
}
```

### Se√ß√£o Models (Modelos de IA)

#### Modelo Principal

```json
"main": {
  "provider": "ollama",
  "modelId": "llama3.2:3b",
  "maxTokens": 64000,
  "temperature": 0.2,
  "top_p": 0.9,
  "repeat_penalty": 1.1,
  "baseURL": "http://localhost:11434/api"
}
```

**Par√¢metros Explicados:**

- `provider`: Provedor do modelo (ollama, anthropic, openai, etc.)
- `modelId`: Identificador do modelo
- `maxTokens`: M√°ximo de tokens para resposta
- `temperature`: Criatividade (0.0 = determin√≠stico, 1.0 = criativo)
- `top_p`: Nucleus sampling (0.9 = 90% dos tokens mais prov√°veis)
- `repeat_penalty`: Penalidade para repeti√ß√£o (1.0 = sem penalidade)
- `baseURL`: URL base para APIs HTTP

#### Configura√ß√µes Alternativas de Modelos

**Para Modelos OpenAI:**

```json
"main": {
  "provider": "openai",
  "modelId": "gpt-4-turbo-preview",
  "maxTokens": 4000,
  "temperature": 0.3,
  "top_p": 0.9,
  "baseURL": "https://api.openai.com/v1"
}
```

**Para Modelos Anthropic:**

```json
"fallback": {
  "provider": "anthropic",
  "modelId": "claude-3-5-sonnet-20241022",
  "maxTokens": 8000,
  "temperature": 0.2,
  "top_p": 0.9,
  "baseURL": "https://api.anthropic.com"
}
```

### Se√ß√£o Global

```json
"global": {
  "logLevel": "info",
  "debug": false,
  "defaultNumTasks": 10,
  "defaultSubtasks": 5,
  "defaultPriority": "medium",
  "projectName": "Aurora Project",
  "ollamaBaseURL": "http://localhost:11434/api",
  "responseLanguage": "Portugu√™s",
  "enableCodebaseAnalysis": true,
  "enableProxy": false,
  "anonymousTelemetry": true,
  "mcpIntegration": true,
  "cursorIntegration": true,
  "vscodeIntegration": true,
  "maxConcurrentRequests": 3,
  "enableCache": true,
  "cacheTimeout": 3600
}
```

**Configura√ß√µes para Produ√ß√£o:**

```json
"global": {
  "logLevel": "warn",
  "debug": false,
  "anonymousTelemetry": false,
  "maxConcurrentRequests": 5,
  "enableCache": true,
  "cacheTimeout": 7200
}
```

**Configura√ß√µes para Desenvolvimento:**

```json
"global": {
  "logLevel": "debug",
  "debug": true,
  "anonymousTelemetry": false,
  "maxConcurrentRequests": 1,
  "enableCache": false
}
```

---

## ü§ñ CONFIGURA√á√ÉO DE MODELOS

### Lista de Modelos Suportados

#### Modelos Ollama (Locais)

| Modelo                | Tamanho | Par√¢metros | Uso Recomendado              |
| --------------------- | ------- | ---------- | ---------------------------- |
| `llama3.2:3b`         | 2.0GB   | 3.2B       | Tarefas gerais, expans√£o     |
| `llama3.2:1b`         | 1.0GB   | 1.0B       | Tarefas simples, performance |
| `qwen3:4b`            | 2.5GB   | 4.0B       | Programa√ß√£o, c√≥digo          |
| `qwen3:1.5b`          | 1.0GB   | 1.5B       | Programa√ß√£o leve             |
| `codellama:7b`        | 3.8GB   | 7.0B       | Desenvolvimento avan√ßado     |
| `mistral:7b`          | 4.1GB   | 7.0B       | Tarefas gerais avan√ßadas     |
| `deepseek-coder:6.7b` | 3.9GB   | 6.7B       | Programa√ß√£o especializada    |

#### Modelos de APIs Externas

| Provedor       | Modelos Principais                   | Custo Aproximado     |
| -------------- | ------------------------------------ | -------------------- |
| **Anthropic**  | claude-3-7-sonnet, claude-3-5-sonnet | $3-15/1M tokens      |
| **OpenAI**     | gpt-4-turbo, gpt-4, gpt-3.5-turbo    | $0.01-0.03/1K tokens |
| **Google**     | gemini-pro, gemini-pro-vision        | $0.0005/1K tokens    |
| **Perplexity** | sonar, sonar-small                   | $5/1M tokens         |

### Configura√ß√£o de Performance

#### Para GTX 1650 4GB (Configura√ß√£o Atual)

```json
{
  "main": {
    "provider": "ollama",
    "modelId": "llama3.2:3b",
    "maxTokens": 32000,
    "temperature": 0.2
  },
  "code": {
    "provider": "ollama",
    "modelId": "qwen3:4b",
    "maxTokens": 16000,
    "temperature": 0.1
  }
}
```

#### Para GPUs Mais Poderosas

```json
{
  "main": {
    "provider": "ollama",
    "modelId": "mistral:7b",
    "maxTokens": 64000,
    "temperature": 0.2
  },
  "code": {
    "provider": "ollama",
    "modelId": "codellama:7b",
    "maxTokens": 32000,
    "temperature": 0.1
  }
}
```

#### Para CPUs (Sem GPU)

```json
{
  "main": {
    "provider": "ollama",
    "modelId": "llama3.2:1b",
    "maxTokens": 16000,
    "temperature": 0.2,
    "cpuOnly": true
  },
  "fallback": {
    "provider": "anthropic",
    "modelId": "claude-3-haiku-20240307",
    "maxTokens": 4000,
    "temperature": 0.2
  }
}
```

---

## ‚öôÔ∏è CONFIGURA√á√ïES DO SISTEMA

### Configura√ß√£o do Ollama

#### SystemD Service

```ini
# /etc/systemd/system/ollama.service
[Unit]
Description=Ollama Service
After=network.target

[Service]
Type=notify
ExecStart=/usr/local/bin/ollama serve
User=ollama
Group=ollama
Restart=always
RestartSec=3
Environment="OLLAMA_HOST=0.0.0.0:11434"
Environment="OLLAMA_ORIGINS=*"
Environment="OLLAMA_MAX_LOADED_MODELS=2"
Environment="OLLAMA_MAX_QUEUE=5"

[Install]
WantedBy=multi-user.target
```

#### Vari√°veis de Ambiente do Ollama

```bash
# /etc/environment ou ~/.bashrc
export OLLAMA_HOST="0.0.0.0:11434"
export OLLAMA_ORIGINS="*"
export OLLAMA_MAX_LOADED_MODELS="2"
export OLLAMA_MAX_QUEUE="5"
export OLLAMA_FLASH_ATTENTION="1"
```

### Configura√ß√£o do Node.js

#### NVM Configuration

```bash
# ~/.nvm/nvmrc
20.12.0
```

#### NPM Global Config

```bash
# ~/.npmrc
prefix=/home/helton/.config/nvm/versions/node/v24.12.0
cache=/home/helton/.npm
```

---

## üìÑ TEMPLATES DE CONFIGURA√á√ÉO

### Template B√°sico (.env)

```bash
# Template b√°sico para novo projeto
OLLAMA_BASE_URL="http://localhost:11434/api"
OLLAMA_API_KEY=""
TASK_MASTER_TOOLS="standard"
LOG_LEVEL="info"
DEBUG="false"
PROJECT_NAME="Nome do Projeto"
RESPONSE_LANGUAGE="Portugu√™s"
ENABLE_CODEBASE_ANALYSIS="true"
DEFAULT_NUM_TASKS="10"
DEFAULT_SUBTASKS="5"
DEFAULT_PRIORITY="medium"
```

### Template de Desenvolvimento

```json
{
  "mcpServers": {
    "task-master-ai": {
      "command": "npx",
      "args": ["-y", "task-master-ai"],
      "env": {
        "TASK_MASTER_TOOLS": "advanced",
        "DEBUG": "true",
        "LOG_LEVEL": "debug"
      },
      "timeout": 60000,
      "retryLimit": 5
    }
  },
  "global": {
    "debug": true,
    "logLevel": "debug",
    "anonymousTelemetry": false
  }
}
```

### Template de Produ√ß√£o

```json
{
  "mcpServers": {
    "task-master-ai": {
      "command": "npx",
      "args": ["-y", "task-master-ai"],
      "env": {
        "TASK_MASTER_TOOLS": "standard",
        "DEBUG": "false",
        "LOG_LEVEL": "warn"
      },
      "timeout": 15000,
      "retryLimit": 2
    }
  },
  "global": {
    "debug": false,
    "logLevel": "warn",
    "anonymousTelemetry": true,
    "enableCache": true,
    "cacheTimeout": 7200
  }
}
```

---

## ‚úÖ VALIDA√á√ÉO DE CONFIGURA√á√ïES

### Script de Valida√ß√£o

```bash
#!/bin/bash
# save as: scripts/validate-config.sh

echo "üîç VALIDANDO CONFIGURA√á√ïES..."

ERRORS=0

# 1. Validar .env
echo "1. Validando .env..."
if [ -f ".env" ]; then
    # Verificar vari√°veis obrigat√≥rias
    if ! grep -q "OLLAMA_BASE_URL" .env; then
        echo "   ‚ùå OLLAMA_BASE_URL n√£o encontrado"
        ERRORS=$((ERRORS + 1))
    fi

    if ! grep -q "TASK_MASTER_TOOLS" .env; then
        echo "   ‚ùå TASK_MASTER_TOOLS n√£o encontrado"
        ERRORS=$((ERRORS + 1))
    fi

    echo "   ‚úÖ .env v√°lido"
else
    echo "   ‚ö†Ô∏è  .env n√£o encontrado"
fi

# 2. Validar .cursor/mcp.json
echo "2. Validando .cursor/mcp.json..."
if [ -f ".cursor/mcp.json" ]; then
    if cat .cursor/mcp.json | jq . > /dev/null 2>&1; then
        # Verificar estrutura MCP
        if cat .cursor/mcp.json | jq -e '.mcpServers."task-master-ai"' > /dev/null 2>&1; then
            echo "   ‚úÖ .cursor/mcp.json v√°lido"
        else
            echo "   ‚ùå Estrutura MCP inv√°lida"
            ERRORS=$((ERRORS + 1))
        fi
    else
        echo "   ‚ùå JSON inv√°lido"
        ERRORS=$((ERRORS + 1))
    fi
else
    echo "   ‚ùå .cursor/mcp.json n√£o encontrado"
    ERRORS=$((ERRORS + 1))
fi

# 3. Validar .taskmaster/config.json
echo "3. Validando .taskmaster/config.json..."
if [ -f ".taskmaster/config.json" ]; then
    if cat .taskmaster/config.json | jq . > /dev/null 2>&1; then
        # Verificar se√ß√£o models
        if cat .taskmaster/config.json | jq -e '.models.main' > /dev/null 2>&1; then
            echo "   ‚úÖ .taskmaster/config.json v√°lido"
        else
            echo "   ‚ùå Se√ß√£o models n√£o encontrada"
            ERRORS=$((ERRORS + 1))
        fi
    else
        echo "   ‚ùå JSON inv√°lido"
        ERRORS=$((ERRORS + 1))
    fi
else
    echo "   ‚ö†Ô∏è  .taskmaster/config.json n√£o encontrado"
fi

# 4. Validar conectividade Ollama
echo "4. Validando conectividade Ollama..."
if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
    MODEL_COUNT=$(curl -s http://localhost:11434/api/tags | jq '.models | length' 2>/dev/null || echo "0")
    if [ "$MODEL_COUNT" -gt 0 ]; then
        echo "   ‚úÖ Ollama OK ($MODEL_COUNT modelos)"
    else
        echo "   ‚ö†Ô∏è  Ollama responde mas sem modelos"
    fi
else
    echo "   ‚ùå Ollama n√£o responde"
    ERRORS=$((ERRORS + 1))
fi

# 5. Validar Task Master AI
echo "5. Validando Task Master AI..."
if command -v task-master &> /dev/null; then
    if task-master --version > /dev/null 2>&1; then
        echo "   ‚úÖ Task Master AI OK"
    else
        echo "   ‚ùå Task Master AI n√£o responde"
        ERRORS=$((ERRORS + 1))
    fi
else
    echo "   ‚ùå Task Master AI n√£o encontrado"
    ERRORS=$((ERRORS + 1))
fi

# Resultado final
echo ""
if [ $ERRORS -eq 0 ]; then
    echo "‚úÖ TODAS AS CONFIGURA√á√ïES V√ÅLIDAS"
else
    echo "‚ùå $ERRORS ERRO(S) ENCONTRADO(S)"
    echo "Execute o troubleshooting guide para resolver os problemas"
fi
```

### Testes de Conectividade

```bash
# Teste r√°pido de todas as configura√ß√µes
#!/bin/bash
# save as: scripts/connectivity-test.sh

echo "üß™ TESTE DE CONECTIVIDADE COMPLETO"

# Teste 1: Ollama API
echo "1. Testando Ollama API..."
RESPONSE=$(curl -s -w "%{http_code}" http://localhost:11434/api/tags)
HTTP_CODE="${RESPONSE: -3}"
if [ "$HTTP_CODE" = "200" ]; then
    MODELS=$(echo "$RESPONSE" | jq '.models | length' 2>/dev/null || echo "?")
    echo "   ‚úÖ API responde - $MODELS modelos"
else
    echo "   ‚ùå API fail (HTTP: $HTTP_CODE)"
fi

# Teste 2: Modelo espec√≠fico
echo "2. Testando modelo llama3.2:3b..."
if curl -s http://localhost:11434/api/tags | jq -e '.models[] | select(.name == "llama3.2:3b")' > /dev/null; then
    echo "   ‚úÖ Modelo principal OK"
else
    echo "   ‚ùå Modelo principal n√£o encontrado"
fi

# Teste 3: Task Master CLI
echo "3. Testando Task Master CLI..."
if task-master models > /dev/null 2>&1; then
    echo "   ‚úÖ CLI responde"
else
    echo "   ‚ùå CLI n√£o responde"
fi

# Teste 4: Servidor MCP
echo "4. Testando servidor MCP..."
if npx -y task-master-ai --version > /dev/null 2>&1; then
    echo "   ‚úÖ Servidor MCP OK"
else
    echo "   ‚ùå Servidor MCP fail"
fi

# Teste 5: Configura√ß√£o MCP
echo "5. Testando configura√ß√£o MCP..."
if echo '{"method":"tools/list"}' | npx -y task-master-ai > /dev/null 2>&1; then
    echo "   ‚úÖ Ferramentas MCP OK"
else
    echo "   ‚ùå Ferramentas MCP fail"
fi

echo "üèÅ Teste de conectividade conclu√≠do"
```

---

## üíæ MIGRA√á√ÉO E BACKUP

### Script de Backup Completo

```bash
#!/bin/bash
# save as: scripts/backup.sh

BACKUP_DIR="$HOME/.aurora-backups"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="$BACKUP_DIR/aurora-backup-$DATE.tar.gz"

echo "üíæ CRIANDO BACKUP COMPLETO..."

# Criar diret√≥rio se n√£o existir
mkdir -p "$BACKUP_DIR"

# Lista de arquivos para backup
BACKUP_FILES=(
    ".env"
    ".taskmaster/"
    ".cursor/mcp.json"
    ".vscode/mcp.json"
    "scripts/"
    "tools/"
)

# Verificar se arquivos existem
EXISTING_FILES=()
for file in "${BACKUP_FILES[@]}"; do
    if [ -e "$file" ]; then
        EXISTING_FILES+=("$file")
    fi
done

if [ ${#EXISTING_FILES[@]} -eq 0 ]; then
    echo "‚ùå Nenhum arquivo para backup encontrado"
    exit 1
fi

# Criar backup
echo "Arquivos a serem inclu√≠dos:"
printf "   %s\n" "${EXISTING_FILES[@]}"

tar -czf "$BACKUP_FILE" "${EXISTING_FILES[@]}" \
    --exclude='*.log' \
    --exclude='node_modules' \
    --exclude='.git'

if [ $? -eq 0 ]; then
    BACKUP_SIZE=$(du -h "$BACKUP_FILE" | cut -f1)
    echo "‚úÖ Backup criado: $BACKUP_FILE ($BACKUP_SIZE)"

    # Manter apenas os 5 backups mais recentes
    cd "$BACKUP_DIR"
    ls -t aurora-backup-*.tar.gz | tail -n +6 | xargs -r rm --
    echo "üßπ Backups antigos removidos (mantidos 5 mais recentes)"
else
    echo "‚ùå Falha ao criar backup"
    exit 1
fi
```

### Script de Restore

```bash
#!/bin/bash
# save as: scripts/restore.sh

if [ $# -ne 1 ]; then
    echo "Uso: $0 <arquivo_backup.tar.gz>"
    echo "Backups dispon√≠veis:"
    ls -la ~/.aurora-backups/aurora-backup-*.tar.gz 2>/dev/null || echo "Nenhum backup encontrado"
    exit 1
fi

BACKUP_FILE="$1"

if [ ! -f "$BACKUP_FILE" ]; then
    echo "‚ùå Arquivo de backup n√£o encontrado: $BACKUP_FILE"
    exit 1
fi

echo "‚ö†Ô∏è  RESTAURANDO BACKUP..."
echo "Arquivo: $BACKUP_FILE"
echo "Este processo ir√° Sobrescrever arquivos existentes!"
read -p "Continuar? (y/N): " -n 1 -r
echo
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
    echo "Restore cancelado"
    exit 1
fi

# Criar backup do estado atual antes de restaurar
echo "Criando backup do estado atual..."
./scripts/backup.sh

# Extrair backup
echo "Extraindo backup..."
tar -xzf "$BACKUP_FILE"

if [ $? -eq 0 ]; then
    echo "‚úÖ Backup restaurado com sucesso"

    # Validar configura√ß√£o ap√≥s restore
    echo "Validando configura√ß√£o..."
    ./scripts/validate-config.sh

    echo "üîÑ Reinicie o terminal ou execute 'source .env' para carregar as novas configura√ß√µes"
else
    echo "‚ùå Falha ao restaurar backup"
    exit 1
fi
```

### Migra√ß√£o Entre Ambientes

```bash
#!/bin/bash
# save as: scripts/migrate.sh

# Migra√ß√£o de desenvolvimento para produ√ß√£o
MIGRATE_ENV="$1"

if [ -z "$MIGRATE_ENV" ]; then
    echo "Uso: $0 <development|production|staging>"
    exit 1
fi

echo "üîÑ MIGRANDO PARA $MIGRATE_ENV..."

case "$MIGRATE_ENV" in
    "development")
        echo "Configurando para desenvolvimento..."
        # Aplicar configura√ß√µes de desenvolvimento
        jq '.global.debug = true | .global.logLevel = "debug" | .mcp.timeout = 60000' \
            .taskmaster/config.json > .taskmaster/config.json.tmp
        mv .taskmaster/config.json.tmp .taskmaster/config.json

        # Vari√°veis de ambiente para dev
        sed -i 's/DEBUG="false"/DEBUG="true"/' .env
        sed -i 's/LOG_LEVEL="info"/LOG_LEVEL="debug"/' .env
        ;;

    "production")
        echo "Configurando para produ√ß√£o..."
        # Aplicar configura√ß√µes de produ√ß√£o
        jq '.global.debug = false | .global.logLevel = "warn" | .mcp.timeout = 15000' \
            .taskmaster/config.json > .taskmaster/config.json.tmp
        mv .taskmaster/config.json.tmp .taskmaster/config.json

        # Vari√°veis de ambiente para produ√ß√£o
        sed -i 's/DEBUG="true"/DEBUG="false"/' .env
        sed -i 's/LOG_LEVEL="debug"/LOG_LEVEL="warn"/' .env
        ;;

    "staging")
        echo "Configurando para staging..."
        # Configura√ß√µes intermedi√°rias
        jq '.global.debug = false | .global.logLevel = "info" | .mcp.timeout = 30000' \
            .taskmaster/config.json > .taskmaster/config.json.tmp
        mv .taskmaster/config.json.tmp .taskmaster/config.json
        ;;

    *)
        echo "‚ùå Ambiente inv√°lido: $MIGRATE_ENV"
        echo "Use: development, production, ou staging"
        exit 1
        ;;
esac

echo "‚úÖ Migra√ß√£o conclu√≠da para $MIGRATE_ENV"
echo "üîÑ Reinicie os servi√ßos para aplicar as mudan√ßas"
```

---

## üìä MONITORAMENTO DE CONFIGURA√á√ÉO

### Dashboard de Status

```bash
#!/bin/bash
# save as: scripts/config-dashboard.sh

echo "üìä DASHBOARD DE CONFIGURA√á√ÉO - $(date)"
echo "======================================"

# Status dos arquivos de configura√ß√£o
echo "üìÅ ARQUIVOS DE CONFIGURA√á√ÉO:"
echo "   .env: $([ -f .env ] && echo '‚úÖ OK' || echo '‚ùå MISSING')"
echo "   .cursor/mcp.json: $([ -f .cursor/mcp.json ] && echo '‚úÖ OK' || echo '‚ùå MISSING')"
echo "   .vscode/mcp.json: $([ -f .vscode/mcp.json ] && echo '‚úÖ OK' || echo '‚ùå MISSING')"
echo "   .taskmaster/config.json: $([ -f .taskmaster/config.json ] && echo '‚úÖ OK' || echo '‚ùå MISSING')"

# Status dos servi√ßos
echo ""
echo "üîß SERVI√áOS:"
echo "   Task Master AI: $(command -v task-master > /dev/null && echo '‚úÖ OK' || echo '‚ùå MISSING')"
echo "   Ollama API: $(curl -s http://localhost:11434/api/tags > /dev/null && echo '‚úÖ OK' || echo '‚ùå FAIL')"

# Modelos configurados
echo ""
echo "ü§ñ MODELOS CONFIGURADOS:"
if [ -f .taskmaster/config.json ]; then
    MAIN_MODEL=$(jq -r '.models.main.modelId // "N/A"' .taskmaster/config.json 2>/dev/null || echo "N/A")
    echo "   Principal: $MAIN_MODEL"

    CODE_MODEL=$(jq -r '.models.code.modelId // "N/A"' .taskmaster/config.json 2>/dev/null || echo "N/A")
    echo "   C√≥digo: $CODE_MODEL"
fi

# Modelos Ollama dispon√≠veis
echo ""
echo "üì¶ MODELOS OLLAMA DISPON√çVEIS:"
if command -v ollama > /dev/null; then
    MODEL_COUNT=$(ollama list 2>/dev/null | tail -n +2 | wc -l || echo "0")
    echo "   Total: $MODEL_COUNT modelos"

    # Mostrar principais
    ollama list 2>/dev/null | head -5 | tail -n +2 | while read line; do
        NAME=$(echo "$line" | awk '{print $1}')
        SIZE=$(echo "$line" | awk '{print $3}')
        echo "   ‚Ä¢ $NAME ($SIZE)"
    done
fi

# Uso de recursos
echo ""
echo "üíª RECURSOS DO SISTEMA:"
echo "   RAM: $(free -h | awk 'NR==2{printf "%.1f%%", $3/$2*100}')"
echo "   Disco: $(df -h / | awk 'NR==2{print $5}')"

if command -v nvidia-smi > /dev/null 2>&1; then
    GPU_USAGE=$(nvidia-smi --query-gpu=memory.used,memory.total --format=csv,noheader,nounits 2>/dev/null | head -1)
    echo "   GPU: $GPU_USAGE"
fi

echo "======================================"
```

---

## üèÅ CONCLUS√ÉO

Este guia de refer√™ncia consolida **todas as configura√ß√µes** do sistema Task Master AI + Ollama:

### ‚úÖ Configura√ß√µes Documentadas

- **4 arquivos principais** de configura√ß√£o (.env, mcp.json, config.json)
- **15+ vari√°veis de ambiente** com explica√ß√µes
- **Templates para 3 ambientes** (dev, staging, prod)
- **Scripts de valida√ß√£o** e migra√ß√£o
- **20+ modelos suportados** com recomenda√ß√µes

### üéØ Para Cada Situa√ß√£o

- **Desenvolvimento:** Debug habilitado, logs detalhados
- **Produ√ß√£o:** Performance otimizada, logs m√≠nimos
- **Troubleshooting:** Valida√ß√£o autom√°tica, health checks
- **Migra√ß√£o:** Backup/restore automatizado

### üîß Manuten√ß√£o

- **Valida√ß√£o cont√≠nua** com scripts automatizados
- **Monitoramento de recursos** em tempo real
- **Backup autom√°tico** com rota√ß√£o
- **Recovery procedures** testadas

**Sistema totalmente configur√°vel e documentado!** üìö

---

**Refer√™ncia Completa de Configura√ß√µes**  
**Vers√£o:** 1.0  
**Data:** 03 de Janeiro de 2026  
**Total de Par√¢metros:** 50+ documentados
